{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import evolution\n",
    "from config import Config\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "import os\n",
    "import evolution, evolution_operations\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "\n",
    "config_settings = {\n",
    "    'n_gen': 1,\n",
    "    'dataset': 'mnist',\n",
    "    'pop_size': 2,\n",
    "    'n_epochs': 1,\n",
    "    'number_of_objectives': 1}\n",
    "\n",
    "iterations = 1\n",
    "iteration_for_second_objective = 2\n",
    "\n",
    "for i in range(iterations):\n",
    "    if i == iteration_for_second_objective: config_settings['obj_num'] = 2\n",
    "\n",
    "    config = Config(config_settings)      \n",
    "    problem = evolution.EVProblem(config)\n",
    "    algorithm = NSGA2(pop_size=config.pop_size,\n",
    "                sampling=evolution_operations.SamplingFromSmall(),\n",
    "                mutation=evolution_operations.MutationFromSmall(),\n",
    "                eliminate_duplicates=True)\n",
    "    res = minimize(problem,\n",
    "                    algorithm, \n",
    "                    callback=evolution.do_every_generations,\n",
    "                    termination=config.termination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CNN MNIST digits classification\n",
    "3-layer CNN for MNIST digits classification \n",
    "First 2 layers - Conv2D-ReLU-MaxPool\n",
    "3rd layer - Conv2D-ReLU-Dropout\n",
    "4th layer - Dense(10)\n",
    "Output Activation - softmax\n",
    "Optimizer - Adam\n",
    "99.4% test accuracy in 10epochs\n",
    "https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# load mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# compute the number of labels\n",
    "num_labels = len(np.unique(y_train))\n",
    "\n",
    "# convert to one-hot vector\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# input image dimensions\n",
    "image_size = x_train.shape[1]\n",
    "# resize and normalize\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# network parameters\n",
    "# image is processed as is (square grayscale)\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "filters = 64\n",
    "dropout = 0.4\n",
    "\n",
    "# model is a stack of CNN-ReLU-MaxPooling\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size))\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size))\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation='relu'))\n",
    "model.add(Flatten())\n",
    "# dropout added as regularizer\n",
    "# model.add(Dropout(dropout))\n",
    "# output layer is 10-dim one-hot vector\n",
    "print(num_labels)\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# enable this if pydot can be installed\n",
    "# pip install pydot\n",
    "#plot_model(model, to_file='cnn-mnist.png', show_shapes=True)\n",
    "\n",
    "# loss function for one-hot vector\n",
    "# use of adam optimizer\n",
    "# accuracy is good metric for classification tasks\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# train the network\n",
    "model.fit(x_train, y_train, epochs=10, use_multiprocessing=True, batch_size=batch_size)\n",
    "\n",
    "_, acc = model.evaluate(x_test,\n",
    "                        y_test,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CNN MNIST digits classification\n",
    "3-layer CNN for MNIST digits classification \n",
    "First 2 layers - Conv2D-ReLU-MaxPool\n",
    "3rd layer - Conv2D-ReLU-Dropout\n",
    "4th layer - Dense(10)\n",
    "Output Activation - softmax\n",
    "Optimizer - Adam\n",
    "99.4% test accuracy in 10epochs\n",
    "https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from data_set import DataSet\n",
    "\n",
    "# load mnist dataset\n",
    "ds_train, ds_test, ds_info = DataSet('mnist', batch_size=128)\n",
    "\n",
    "# # compute the number of labels\n",
    "# num_labels = len(np.unique(y_train))\n",
    "\n",
    "# # convert to one-hot vector\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "\n",
    "# # input image dimensions\n",
    "# image_size = x_train.shape[1]\n",
    "# # resize and normalize\n",
    "# x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "# x_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
    "# x_train = x_train.astype('float32') / 255\n",
    "# x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# network parameters\n",
    "# image is processed as is (square grayscale)\n",
    "# input_shape = (image_size, image_size, 1)\n",
    "batch_size = 32\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "filters = 64\n",
    "dropout = 0.4\n",
    "\n",
    "# model is a stack of CNN-ReLU-MaxPooling\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size = kernel_size, \n",
    "                 activation='relu',\n",
    "                 input_shape=ds_info.features['image'].shape))\n",
    "model.add(MaxPooling2D(pool_size))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 activation='relu'))\n",
    "model.add(Flatten())\n",
    "# dropout added as regularizer\n",
    "model.add(Dropout(dropout))\n",
    "# output layer is 10-dim one-hot vector\n",
    "model.add(Dense(ds_info.features['label'].num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# enable this if pydot can be installed\n",
    "# pip install pydot\n",
    "#plot_model(model, to_file='cnn-mnist.png', show_shapes=True)\n",
    "\n",
    "# loss function for one-hot vector\n",
    "# use of adam optimizer\n",
    "# accuracy is good metric for classification tasks\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# train the network\n",
    "model.fit(ds_train, epochs=10, batch_size=batch_size)\n",
    "\n",
    "_, acc = model.evaluate(ds_test,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "\n",
    "from data_set import DataSet\n",
    "\n",
    "# load mnist dataset\n",
    "ds_train, ds_test, ds_info = DataSet('cifar10', batch_size=128)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=ds_info.features['image'].shape, filters=96, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(ds_info.features['label'].num_classes, activation=\"softmax\"))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 128\n",
    "callbacks_list = None\n",
    "H = model.fit(ds_train, validation_data=ds_test, \n",
    "              epochs=n_epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a5c1c80b3bcd0e5f62b21a0e810a38f905366c5916006723ffe06d666856c32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
